{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from datasets import load_dataset\n",
    "\n",
    "def get_story_in_lang(lang):\n",
    "    ds_raw = load_dataset('opus_books', 'en-it', split = 'train')\n",
    "    for item in ds_raw:\n",
    "        yield item['translation'][lang]\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[SOS]\", \"[EOS]\", \"[PAD]\"])\n",
    "\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "tokenizer.train_from_iterator(get_story_in_lang('en'), trainer = trainer)\n",
    "tokenizer.save(\"tokenizer-wiki.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.5119e-02, 6.3096e-04, 1.5849e-05, 3.9811e-07])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.pow(10,  torch.arange(0,5)*-4/512)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9647, 0.9647, 0.9647, 0.9647],\n",
       "         [0.9306, 0.9306, 0.9306, 0.9306],\n",
       "         [0.8977, 0.8977, 0.8977, 0.8977],\n",
       "         [0.8660, 0.8660, 0.8660, 0.8660],\n",
       "         [0.8354, 0.8354, 0.8354, 0.8354]],\n",
       "\n",
       "        [[0.9647, 0.9647, 0.9647, 0.9647],\n",
       "         [0.9306, 0.9306, 0.9306, 0.9306],\n",
       "         [0.8977, 0.8977, 0.8977, 0.8977],\n",
       "         [0.8660, 0.8660, 0.8660, 0.8660],\n",
       "         [0.8354, 0.8354, 0.8354, 0.8354]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.ones(2, 5,4)\n",
    "\n",
    "\n",
    "pe[: ,:] / (10000**((2*torch.arange(1, 6).unsqueeze(1)/512)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.5119e-02, 6.3096e-04])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_term = torch.exp(torch.arange(0, 5, 2) * -(np.log(10000.0) / 5))\n",
    "div_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 5, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l  = torch.arange(5).unsqueeze(1)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.1544e-03, 4.6416e-06])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_term = torch.exp(torch.arange(0, 6, 2) * -(math.log(10000.0) / 3))\n",
    "div_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.ones(5,6)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe[:,0::2] = torch.sin(l/div_term)\n",
    "pe[:, 1::2] = torch.cos(l/div_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403, -0.7151,  0.6990, -0.6469,  0.7626],\n",
       "        [ 0.9093, -0.4161, -0.9997, -0.0229, -0.9866,  0.1631],\n",
       "        [ 0.1411, -0.9900, -0.6824, -0.7310, -0.8579, -0.5139],\n",
       "        [-0.7568, -0.6536,  0.0457, -0.9990, -0.3218, -0.9468]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.,  9., 16.])\n"
     ]
    }
   ],
   "source": [
    "pe = pe[:,0::2] * div_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =  torch.ones(3, 5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(1, 5)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(tensor([[0, 1],\n",
      "        [4, 5],\n",
      "        [8, 9]]), tensor([[ 2,  3],\n",
      "        [ 6,  7],\n",
      "        [10, 11]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "tensor = torch.arange(12).reshape(3, 4)  # Example tensor of shape (3, 4)\n",
    "\n",
    "# Define the number of parts (n)\n",
    "n = 2\n",
    "\n",
    "\n",
    "print(tensor.size(1))\n",
    "# Calculate the number of columns per part\n",
    "columns_per_part = tensor.size(1) // n\n",
    "\n",
    "# Split the tensor into n parts horizontally\n",
    "parts = torch.split(tensor, columns_per_part, dim=1)\n",
    "\n",
    "print(parts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7,8,9]])\n",
    "original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 6]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reshaped_tensor \u001b[39m=\u001b[39m original_tensor\u001b[39m.\u001b[39;49mview(\u001b[39m1\u001b[39;49m, \u001b[39m6\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m reshaped_tensor\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 6]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "reshaped_tensor = original_tensor.view(1, 6)\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a tensor with 8 columns\n",
    "original_tensor = torch.randn((4,3,12))  # 10 rows, 8 columns\n",
    "\n",
    "# Reshape into two tensors with 4 columns each\n",
    "# tensor1 = original_tensor.view(10, 4)\n",
    "# tensor2 = original_tensor.view(10, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3569e+00,  8.1420e-01, -5.0513e-01,  7.1561e-01, -7.5575e-01,\n",
       "          -1.6054e+00,  1.4355e-01,  5.4012e-01,  2.2200e-02, -1.2007e+00,\n",
       "          -1.6061e-01,  7.2470e-02],\n",
       "         [ 2.8545e-01,  1.1777e+00, -2.9516e-01, -1.5715e+00,  1.6251e-01,\n",
       "           7.3575e-01, -1.1754e+00, -9.0543e-01,  8.2494e-03, -7.2159e-01,\n",
       "          -1.3167e+00, -7.4680e-01],\n",
       "         [-1.0934e-01,  2.2632e-01, -8.6194e-01,  6.0491e-01,  1.4358e+00,\n",
       "           4.0445e-01,  1.7612e-01, -5.8278e-01,  3.3554e-01, -1.4013e-01,\n",
       "           6.1766e-01,  8.2693e-02]],\n",
       "\n",
       "        [[-2.4070e-01,  1.9078e-01,  8.7953e-01, -1.5625e+00, -2.7589e-01,\n",
       "          -5.4136e-01,  1.3281e+00, -1.2808e-01, -1.4467e+00,  1.9439e+00,\n",
       "          -7.2534e-01, -1.4454e+00],\n",
       "         [-1.8248e+00,  1.8724e+00, -4.3380e-01,  4.1128e-01,  7.7384e-03,\n",
       "           6.5897e-01,  1.7670e-01,  1.1206e+00, -8.4288e-04,  1.0662e+00,\n",
       "          -4.7448e-01,  1.3378e+00],\n",
       "         [ 1.0233e-01,  4.1956e-01,  4.3054e-01,  1.4949e-01, -1.5244e+00,\n",
       "          -1.0316e+00,  4.3986e-01,  1.4129e+00, -1.8544e+00,  9.6458e-01,\n",
       "           1.1179e+00,  6.8580e-02]],\n",
       "\n",
       "        [[ 4.9096e-01, -3.8171e-01, -1.7794e+00, -4.1025e-01,  4.5779e-01,\n",
       "          -4.7462e-02, -9.3075e-01,  7.7491e-01,  5.3956e-01,  9.7189e-01,\n",
       "          -1.1683e+00, -9.7532e-01],\n",
       "         [ 1.6933e+00, -1.8487e+00, -9.1667e-01,  1.6123e-01,  2.4587e-01,\n",
       "           7.2606e-01,  1.2127e-01,  2.7591e-01,  4.5904e-01,  1.3755e+00,\n",
       "          -3.9702e-01, -5.6439e-01],\n",
       "         [-3.5436e-01, -1.8607e+00, -7.0137e-01,  1.8585e+00,  1.1371e-01,\n",
       "           1.5679e+00,  1.1983e+00, -2.1200e-01, -7.1945e-01,  3.0538e-01,\n",
       "          -5.7386e-01,  3.5155e-01]],\n",
       "\n",
       "        [[ 3.4385e-01, -2.1005e-01, -2.4129e-01,  1.4427e+00, -3.6391e-01,\n",
       "           1.2471e+00, -1.3470e-01, -5.7894e-01, -1.5467e+00, -1.7500e+00,\n",
       "          -6.7932e-01, -1.5722e+00],\n",
       "         [ 1.2907e-01,  3.1772e-01,  3.5648e-01,  1.9164e+00, -1.0353e+00,\n",
       "          -7.1900e-01,  1.0942e+00, -1.7182e+00,  1.4536e-01, -2.5355e-01,\n",
       "          -1.4931e+00,  2.6863e+00],\n",
       "         [ 1.0015e+00,  9.0267e-01,  1.3820e-01,  3.4913e-01, -8.1903e-02,\n",
       "          -1.1779e+00,  3.5350e-01,  1.1160e+00,  2.8404e-02,  2.7722e+00,\n",
       "           1.9059e+00,  3.5625e-01]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.3569e+00,  8.1420e-01, -5.0513e-01],\n",
       "          [ 7.1561e-01, -7.5575e-01, -1.6054e+00],\n",
       "          [ 1.4355e-01,  5.4012e-01,  2.2200e-02],\n",
       "          [-1.2007e+00, -1.6061e-01,  7.2470e-02]],\n",
       "\n",
       "         [[ 2.8545e-01,  1.1777e+00, -2.9516e-01],\n",
       "          [-1.5715e+00,  1.6251e-01,  7.3575e-01],\n",
       "          [-1.1754e+00, -9.0543e-01,  8.2494e-03],\n",
       "          [-7.2159e-01, -1.3167e+00, -7.4680e-01]],\n",
       "\n",
       "         [[-1.0934e-01,  2.2632e-01, -8.6194e-01],\n",
       "          [ 6.0491e-01,  1.4358e+00,  4.0445e-01],\n",
       "          [ 1.7612e-01, -5.8278e-01,  3.3554e-01],\n",
       "          [-1.4013e-01,  6.1766e-01,  8.2693e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.4070e-01,  1.9078e-01,  8.7953e-01],\n",
       "          [-1.5625e+00, -2.7589e-01, -5.4136e-01],\n",
       "          [ 1.3281e+00, -1.2808e-01, -1.4467e+00],\n",
       "          [ 1.9439e+00, -7.2534e-01, -1.4454e+00]],\n",
       "\n",
       "         [[-1.8248e+00,  1.8724e+00, -4.3380e-01],\n",
       "          [ 4.1128e-01,  7.7384e-03,  6.5897e-01],\n",
       "          [ 1.7670e-01,  1.1206e+00, -8.4288e-04],\n",
       "          [ 1.0662e+00, -4.7448e-01,  1.3378e+00]],\n",
       "\n",
       "         [[ 1.0233e-01,  4.1956e-01,  4.3054e-01],\n",
       "          [ 1.4949e-01, -1.5244e+00, -1.0316e+00],\n",
       "          [ 4.3986e-01,  1.4129e+00, -1.8544e+00],\n",
       "          [ 9.6458e-01,  1.1179e+00,  6.8580e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 4.9096e-01, -3.8171e-01, -1.7794e+00],\n",
       "          [-4.1025e-01,  4.5779e-01, -4.7462e-02],\n",
       "          [-9.3075e-01,  7.7491e-01,  5.3956e-01],\n",
       "          [ 9.7189e-01, -1.1683e+00, -9.7532e-01]],\n",
       "\n",
       "         [[ 1.6933e+00, -1.8487e+00, -9.1667e-01],\n",
       "          [ 1.6123e-01,  2.4587e-01,  7.2606e-01],\n",
       "          [ 1.2127e-01,  2.7591e-01,  4.5904e-01],\n",
       "          [ 1.3755e+00, -3.9702e-01, -5.6439e-01]],\n",
       "\n",
       "         [[-3.5436e-01, -1.8607e+00, -7.0137e-01],\n",
       "          [ 1.8585e+00,  1.1371e-01,  1.5679e+00],\n",
       "          [ 1.1983e+00, -2.1200e-01, -7.1945e-01],\n",
       "          [ 3.0538e-01, -5.7386e-01,  3.5155e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.4385e-01, -2.1005e-01, -2.4129e-01],\n",
       "          [ 1.4427e+00, -3.6391e-01,  1.2471e+00],\n",
       "          [-1.3470e-01, -5.7894e-01, -1.5467e+00],\n",
       "          [-1.7500e+00, -6.7932e-01, -1.5722e+00]],\n",
       "\n",
       "         [[ 1.2907e-01,  3.1772e-01,  3.5648e-01],\n",
       "          [ 1.9164e+00, -1.0353e+00, -7.1900e-01],\n",
       "          [ 1.0942e+00, -1.7182e+00,  1.4536e-01],\n",
       "          [-2.5355e-01, -1.4931e+00,  2.6863e+00]],\n",
       "\n",
       "         [[ 1.0015e+00,  9.0267e-01,  1.3820e-01],\n",
       "          [ 3.4913e-01, -8.1903e-02, -1.1779e+00],\n",
       "          [ 3.5350e-01,  1.1160e+00,  2.8404e-02],\n",
       "          [ 2.7722e+00,  1.9059e+00,  3.5625e-01]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this sapes the tensor into (batch, num_heads, seq_len, d_k)\n",
    "# 4,4,3,3\n",
    "j = original_tensor.view(4, 3,4, 3)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.3569e+00,  8.1420e-01, -5.0513e-01],\n",
       "          [ 2.8545e-01,  1.1777e+00, -2.9516e-01],\n",
       "          [-1.0934e-01,  2.2632e-01, -8.6194e-01]],\n",
       "\n",
       "         [[ 7.1561e-01, -7.5575e-01, -1.6054e+00],\n",
       "          [-1.5715e+00,  1.6251e-01,  7.3575e-01],\n",
       "          [ 6.0491e-01,  1.4358e+00,  4.0445e-01]],\n",
       "\n",
       "         [[ 1.4355e-01,  5.4012e-01,  2.2200e-02],\n",
       "          [-1.1754e+00, -9.0543e-01,  8.2494e-03],\n",
       "          [ 1.7612e-01, -5.8278e-01,  3.3554e-01]],\n",
       "\n",
       "         [[-1.2007e+00, -1.6061e-01,  7.2470e-02],\n",
       "          [-7.2159e-01, -1.3167e+00, -7.4680e-01],\n",
       "          [-1.4013e-01,  6.1766e-01,  8.2693e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.4070e-01,  1.9078e-01,  8.7953e-01],\n",
       "          [-1.8248e+00,  1.8724e+00, -4.3380e-01],\n",
       "          [ 1.0233e-01,  4.1956e-01,  4.3054e-01]],\n",
       "\n",
       "         [[-1.5625e+00, -2.7589e-01, -5.4136e-01],\n",
       "          [ 4.1128e-01,  7.7384e-03,  6.5897e-01],\n",
       "          [ 1.4949e-01, -1.5244e+00, -1.0316e+00]],\n",
       "\n",
       "         [[ 1.3281e+00, -1.2808e-01, -1.4467e+00],\n",
       "          [ 1.7670e-01,  1.1206e+00, -8.4288e-04],\n",
       "          [ 4.3986e-01,  1.4129e+00, -1.8544e+00]],\n",
       "\n",
       "         [[ 1.9439e+00, -7.2534e-01, -1.4454e+00],\n",
       "          [ 1.0662e+00, -4.7448e-01,  1.3378e+00],\n",
       "          [ 9.6458e-01,  1.1179e+00,  6.8580e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 4.9096e-01, -3.8171e-01, -1.7794e+00],\n",
       "          [ 1.6933e+00, -1.8487e+00, -9.1667e-01],\n",
       "          [-3.5436e-01, -1.8607e+00, -7.0137e-01]],\n",
       "\n",
       "         [[-4.1025e-01,  4.5779e-01, -4.7462e-02],\n",
       "          [ 1.6123e-01,  2.4587e-01,  7.2606e-01],\n",
       "          [ 1.8585e+00,  1.1371e-01,  1.5679e+00]],\n",
       "\n",
       "         [[-9.3075e-01,  7.7491e-01,  5.3956e-01],\n",
       "          [ 1.2127e-01,  2.7591e-01,  4.5904e-01],\n",
       "          [ 1.1983e+00, -2.1200e-01, -7.1945e-01]],\n",
       "\n",
       "         [[ 9.7189e-01, -1.1683e+00, -9.7532e-01],\n",
       "          [ 1.3755e+00, -3.9702e-01, -5.6439e-01],\n",
       "          [ 3.0538e-01, -5.7386e-01,  3.5155e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.4385e-01, -2.1005e-01, -2.4129e-01],\n",
       "          [ 1.2907e-01,  3.1772e-01,  3.5648e-01],\n",
       "          [ 1.0015e+00,  9.0267e-01,  1.3820e-01]],\n",
       "\n",
       "         [[ 1.4427e+00, -3.6391e-01,  1.2471e+00],\n",
       "          [ 1.9164e+00, -1.0353e+00, -7.1900e-01],\n",
       "          [ 3.4913e-01, -8.1903e-02, -1.1779e+00]],\n",
       "\n",
       "         [[-1.3470e-01, -5.7894e-01, -1.5467e+00],\n",
       "          [ 1.0942e+00, -1.7182e+00,  1.4536e-01],\n",
       "          [ 3.5350e-01,  1.1160e+00,  2.8404e-02]],\n",
       "\n",
       "         [[-1.7500e+00, -6.7932e-01, -1.5722e+00],\n",
       "          [-2.5355e-01, -1.4931e+00,  2.6863e+00],\n",
       "          [ 2.7722e+00,  1.9059e+00,  3.5625e-01]]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor.view(4, 3,4, 3).transpose(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3569e+00,  8.1420e-01, -5.0513e-01,  7.1561e-01, -7.5575e-01,\n",
       "          -1.6054e+00,  1.4355e-01,  5.4012e-01,  2.2200e-02, -1.2007e+00,\n",
       "          -1.6061e-01,  7.2470e-02],\n",
       "         [ 2.8545e-01,  1.1777e+00, -2.9516e-01, -1.5715e+00,  1.6251e-01,\n",
       "           7.3575e-01, -1.1754e+00, -9.0543e-01,  8.2494e-03, -7.2159e-01,\n",
       "          -1.3167e+00, -7.4680e-01],\n",
       "         [-1.0934e-01,  2.2632e-01, -8.6194e-01,  6.0491e-01,  1.4358e+00,\n",
       "           4.0445e-01,  1.7612e-01, -5.8278e-01,  3.3554e-01, -1.4013e-01,\n",
       "           6.1766e-01,  8.2693e-02]],\n",
       "\n",
       "        [[-2.4070e-01,  1.9078e-01,  8.7953e-01, -1.5625e+00, -2.7589e-01,\n",
       "          -5.4136e-01,  1.3281e+00, -1.2808e-01, -1.4467e+00,  1.9439e+00,\n",
       "          -7.2534e-01, -1.4454e+00],\n",
       "         [-1.8248e+00,  1.8724e+00, -4.3380e-01,  4.1128e-01,  7.7384e-03,\n",
       "           6.5897e-01,  1.7670e-01,  1.1206e+00, -8.4288e-04,  1.0662e+00,\n",
       "          -4.7448e-01,  1.3378e+00],\n",
       "         [ 1.0233e-01,  4.1956e-01,  4.3054e-01,  1.4949e-01, -1.5244e+00,\n",
       "          -1.0316e+00,  4.3986e-01,  1.4129e+00, -1.8544e+00,  9.6458e-01,\n",
       "           1.1179e+00,  6.8580e-02]],\n",
       "\n",
       "        [[ 4.9096e-01, -3.8171e-01, -1.7794e+00, -4.1025e-01,  4.5779e-01,\n",
       "          -4.7462e-02, -9.3075e-01,  7.7491e-01,  5.3956e-01,  9.7189e-01,\n",
       "          -1.1683e+00, -9.7532e-01],\n",
       "         [ 1.6933e+00, -1.8487e+00, -9.1667e-01,  1.6123e-01,  2.4587e-01,\n",
       "           7.2606e-01,  1.2127e-01,  2.7591e-01,  4.5904e-01,  1.3755e+00,\n",
       "          -3.9702e-01, -5.6439e-01],\n",
       "         [-3.5436e-01, -1.8607e+00, -7.0137e-01,  1.8585e+00,  1.1371e-01,\n",
       "           1.5679e+00,  1.1983e+00, -2.1200e-01, -7.1945e-01,  3.0538e-01,\n",
       "          -5.7386e-01,  3.5155e-01]],\n",
       "\n",
       "        [[ 3.4385e-01, -2.1005e-01, -2.4129e-01,  1.4427e+00, -3.6391e-01,\n",
       "           1.2471e+00, -1.3470e-01, -5.7894e-01, -1.5467e+00, -1.7500e+00,\n",
       "          -6.7932e-01, -1.5722e+00],\n",
       "         [ 1.2907e-01,  3.1772e-01,  3.5648e-01,  1.9164e+00, -1.0353e+00,\n",
       "          -7.1900e-01,  1.0942e+00, -1.7182e+00,  1.4536e-01, -2.5355e-01,\n",
       "          -1.4931e+00,  2.6863e+00],\n",
       "         [ 1.0015e+00,  9.0267e-01,  1.3820e-01,  3.4913e-01, -8.1903e-02,\n",
       "          -1.1779e+00,  3.5350e-01,  1.1160e+00,  2.8404e-02,  2.7722e+00,\n",
       "           1.9059e+00,  3.5625e-01]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.transpose(2,1).view(j.shape[0], j.shape[2], 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0987, -0.9672],\n",
       "        [-0.8051,  1.3027],\n",
       "        [-0.7114,  0.5448]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aj = torch.randn(3,2)\n",
    "aj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0657],\n",
       "        [ 0.2488],\n",
       "        [-0.0833]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jk =torch.mean(aj, dim=1)\n",
    "jk.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[1, 2, 3],\n",
    "                             [4, 0, 0],\n",
    "                             [5, 6, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[1, 2, 0],\n",
      "        [4, 0, 0],\n",
      "        [5, 6, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Define the padding value\n",
    "padding_value = 3\n",
    "\n",
    "# Create the padding mask\n",
    "padding_mask = (input_tensor != padding_value).int()\n",
    "print(padding_mask)\n",
    "\n",
    "masked_tensor = input_tensor * padding_mask\n",
    "\n",
    "print(masked_tensor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.zeros(5,6)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(3,4, 5,6)\n",
    "t.shape\n",
    "f = t * j\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.Embedding(10,2, padding_idx=5)\n",
    "l(torch.tensor([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.ones(3,5)\n",
    "f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.ones(4, 3,5)\n",
    "j\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f + j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

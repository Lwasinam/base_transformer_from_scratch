{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(num):\n",
    "    return num +1\n",
    "\n",
    "\n",
    "x = 3\n",
    "for i in range(10):\n",
    "    x = add(x)\n",
    "print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.0047, -0.7807,  0.1880, -0.3930],\n",
       "          [ 0.4722, -0.0091, -0.4450,  1.6333],\n",
       "          [ 2.3372, -0.6267,  1.8028, -1.3613],\n",
       "          [ 0.6666, -1.1908, -0.9757,  1.2225],\n",
       "          [-0.4613,  0.7895, -1.2481,  0.7646]],\n",
       "\n",
       "         [[-1.3025,  0.4203, -0.0255,  0.7328],\n",
       "          [-0.5811, -0.2708,  0.3745,  1.0871],\n",
       "          [-0.1778, -0.5846, -0.2572, -0.8767],\n",
       "          [-1.3432,  1.5392,  1.2854, -0.0635],\n",
       "          [ 1.2638, -3.3395, -0.7382, -0.6187]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0643, -0.0551,  1.2864,  0.6277],\n",
       "          [-0.0150,  0.6234,  2.1793,  0.4823],\n",
       "          [-1.8973,  0.7574,  1.7489, -1.1594],\n",
       "          [-0.0147, -0.7052,  0.9326,  1.0854],\n",
       "          [ 1.0071, -0.4347, -0.1676, -0.7953]],\n",
       "\n",
       "         [[ 1.0296, -0.9789, -0.0435,  2.7295],\n",
       "          [-0.6247, -1.2609,  1.0908,  1.4704],\n",
       "          [ 0.1000, -0.3370,  1.0904,  0.2444],\n",
       "          [-0.6861, -0.2694,  0.1435, -1.5676],\n",
       "          [-0.9505, -0.0075, -0.9708,  0.2709]]],\n",
       "\n",
       "\n",
       "        [[[-0.1684, -0.5224, -0.6257,  0.8375],\n",
       "          [-0.0730, -0.1074,  0.7378,  0.9168],\n",
       "          [ 0.7768, -1.5355,  0.4126, -1.1523],\n",
       "          [ 1.1010,  0.2361,  0.4244, -0.2539],\n",
       "          [-0.1152,  0.0372,  0.4193, -1.4117]],\n",
       "\n",
       "         [[ 0.9656, -1.4936, -0.8501, -0.3525],\n",
       "          [-0.8572, -0.7369,  0.1405,  1.8601],\n",
       "          [-0.2922, -0.6309, -0.2944, -0.5702],\n",
       "          [ 0.3200, -1.7592,  1.3408, -0.5459],\n",
       "          [ 0.2568,  0.8969,  0.6026,  1.0826]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.randn(3, 2, 5,4)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2213, 0.2289, 0.3019, 0.2480],\n",
       "          [0.2302, 0.2139, 0.2052, 0.3507],\n",
       "          [0.3447, 0.1948, 0.2687, 0.1917],\n",
       "          [0.2629, 0.2001, 0.2026, 0.3344],\n",
       "          [0.2165, 0.2918, 0.2029, 0.2888]],\n",
       "\n",
       "         [[0.2040, 0.2640, 0.2358, 0.2962],\n",
       "          [0.2116, 0.2193, 0.2473, 0.3218],\n",
       "          [0.2686, 0.2411, 0.2621, 0.2282],\n",
       "          [0.1965, 0.3126, 0.2799, 0.2110],\n",
       "          [0.4000, 0.1865, 0.2054, 0.2081]]],\n",
       "\n",
       "\n",
       "        [[[0.2640, 0.2142, 0.2852, 0.2366],\n",
       "          [0.2032, 0.2171, 0.3666, 0.2131],\n",
       "          [0.1907, 0.2418, 0.3730, 0.1945],\n",
       "          [0.2218, 0.2067, 0.2772, 0.2943],\n",
       "          [0.3423, 0.2191, 0.2285, 0.2101]],\n",
       "\n",
       "         [[0.2129, 0.1880, 0.1937, 0.4053],\n",
       "          [0.2034, 0.1972, 0.2745, 0.3249],\n",
       "          [0.2311, 0.2167, 0.3145, 0.2377],\n",
       "          [0.2337, 0.2580, 0.2993, 0.2089],\n",
       "          [0.2189, 0.2667, 0.2184, 0.2959]]],\n",
       "\n",
       "\n",
       "        [[[0.2336, 0.2202, 0.2173, 0.3289],\n",
       "          [0.2237, 0.2226, 0.2680, 0.2857],\n",
       "          [0.3199, 0.2010, 0.2733, 0.2058],\n",
       "          [0.3050, 0.2341, 0.2436, 0.2173],\n",
       "          [0.2460, 0.2559, 0.2917, 0.2064]],\n",
       "\n",
       "         [[0.3650, 0.1997, 0.2101, 0.2252],\n",
       "          [0.1951, 0.1964, 0.2126, 0.3960],\n",
       "          [0.2596, 0.2389, 0.2594, 0.2420],\n",
       "          [0.2381, 0.1945, 0.3591, 0.2083],\n",
       "          [0.2260, 0.2589, 0.2406, 0.2745]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.softmax(pe, dim=-1)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from datasets import load_dataset\n",
    "\n",
    "def get_story_in_lang(lang):\n",
    "    ds_raw = load_dataset('opus_books', 'en-it', split = 'train')\n",
    "    for item in ds_raw:\n",
    "        yield item['translation'][lang]\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[SOS]\", \"[EOS]\", \"[PAD]\"])\n",
    "\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "tokenizer.train_from_iterator(get_story_in_lang('en'), trainer = trainer)\n",
    "tokenizer.save(\"tokenizer-wiki.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.5119e-02, 6.3096e-04, 1.5849e-05, 3.9811e-07])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.pow(10,  torch.arange(0,5)*-4/512)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9647, 0.9647, 0.9647, 0.9647],\n",
       "         [0.9306, 0.9306, 0.9306, 0.9306],\n",
       "         [0.8977, 0.8977, 0.8977, 0.8977],\n",
       "         [0.8660, 0.8660, 0.8660, 0.8660],\n",
       "         [0.8354, 0.8354, 0.8354, 0.8354]],\n",
       "\n",
       "        [[0.9647, 0.9647, 0.9647, 0.9647],\n",
       "         [0.9306, 0.9306, 0.9306, 0.9306],\n",
       "         [0.8977, 0.8977, 0.8977, 0.8977],\n",
       "         [0.8660, 0.8660, 0.8660, 0.8660],\n",
       "         [0.8354, 0.8354, 0.8354, 0.8354]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.ones(2, 5,4)\n",
    "\n",
    "\n",
    "pe[: ,:] / (10000**((2*torch.arange(1, 6).unsqueeze(1)/512)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.5119e-02, 6.3096e-04])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_term = torch.exp(torch.arange(0, 5, 2) * -(np.log(10000.0) / 5))\n",
    "div_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 5, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l  = torch.arange(5).unsqueeze(1)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.1544e-03, 4.6416e-06])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_term = torch.exp(torch.arange(0, 6, 2) * -(math.log(10000.0) / 3))\n",
    "div_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.ones(5,6)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe[:,0::2] = torch.sin(l/div_term)\n",
    "pe[:, 1::2] = torch.cos(l/div_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403, -0.7151,  0.6990, -0.6469,  0.7626],\n",
       "        [ 0.9093, -0.4161, -0.9997, -0.0229, -0.9866,  0.1631],\n",
       "        [ 0.1411, -0.9900, -0.6824, -0.7310, -0.8579, -0.5139],\n",
       "        [-0.7568, -0.6536,  0.0457, -0.9990, -0.3218, -0.9468]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.,  9., 16.])\n"
     ]
    }
   ],
   "source": [
    "pe = pe[:,0::2] * div_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =  torch.ones(3, 5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(1, 5)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(tensor([[0, 1],\n",
      "        [4, 5],\n",
      "        [8, 9]]), tensor([[ 2,  3],\n",
      "        [ 6,  7],\n",
      "        [10, 11]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "tensor = torch.arange(12).reshape(3, 4)  # Example tensor of shape (3, 4)\n",
    "\n",
    "# Define the number of parts (n)\n",
    "n = 2\n",
    "\n",
    "\n",
    "print(tensor.size(1))\n",
    "# Calculate the number of columns per part\n",
    "columns_per_part = tensor.size(1) // n\n",
    "\n",
    "# Split the tensor into n parts horizontally\n",
    "parts = torch.split(tensor, columns_per_part, dim=1)\n",
    "\n",
    "print(parts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7,8,9]])\n",
    "original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 6]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reshaped_tensor \u001b[39m=\u001b[39m original_tensor\u001b[39m.\u001b[39;49mview(\u001b[39m1\u001b[39;49m, \u001b[39m6\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m reshaped_tensor\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 6]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "reshaped_tensor = original_tensor.view(1, 6)\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a tensor with 8 columns\n",
    "original_tensor = torch.randn((4,3,12))  # 10 rows, 8 columns\n",
    "\n",
    "# Reshape into two tensors with 4 columns each\n",
    "# tensor1 = original_tensor.view(10, 4)\n",
    "# tensor2 = original_tensor.view(10, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3747, -0.3154,  1.9973,  1.5016,  0.1367,  0.7747, -0.4879,\n",
       "          -2.2326, -0.3182, -1.1270, -1.4711, -0.3569],\n",
       "         [-0.8798,  0.6050,  0.5201,  1.5696, -1.1369,  1.2308, -0.3219,\n",
       "           1.2360, -0.4541,  0.9117, -1.5560, -0.5282],\n",
       "         [ 0.0861, -0.6723,  2.0650, -0.3342, -0.1066, -0.9368,  0.0530,\n",
       "           1.0489,  0.7111, -0.4072, -0.1465,  0.5948]],\n",
       "\n",
       "        [[-0.5127,  0.5897,  3.1053,  0.6968,  0.6136, -0.1065,  0.1887,\n",
       "           0.7772,  1.0469,  0.8286, -0.1791,  1.1441],\n",
       "         [ 0.3378,  0.5325, -0.1929,  0.0176,  0.5653,  1.3824,  1.2239,\n",
       "           1.4021,  0.2207,  0.1849, -0.9061,  0.4841],\n",
       "         [ 1.2226,  1.5711, -0.4486,  0.2924,  0.1485, -0.8486, -0.1540,\n",
       "          -1.4175,  0.2750, -0.7457,  0.3570, -0.7237]],\n",
       "\n",
       "        [[-0.7684, -0.5854, -1.2868, -0.5021,  0.2955, -1.0912,  0.0700,\n",
       "           1.5920,  0.0055,  0.3954, -0.1545,  0.1759],\n",
       "         [ 2.0958, -1.1765,  0.7071,  2.3668,  0.2622, -0.1157, -1.6553,\n",
       "          -0.3449,  0.3250,  0.5074, -0.6900, -1.3982],\n",
       "         [-0.9462,  0.9571,  2.2896,  0.5583,  1.4044, -1.8133,  0.1952,\n",
       "          -1.6929, -2.0366,  0.7649,  0.9587, -1.3545]],\n",
       "\n",
       "        [[ 0.4751, -0.6453, -1.4215,  1.9821, -0.5885, -0.4824, -0.0136,\n",
       "          -0.3013,  0.0614, -0.0319, -1.8799,  0.6918],\n",
       "         [ 0.4864,  0.0309,  1.7248, -0.6815, -1.0453, -0.2519, -0.9613,\n",
       "          -0.3394, -0.2800, -1.2815, -0.4324, -0.5585],\n",
       "         [ 0.6930, -1.6747, -0.0148,  0.7716, -0.7769, -0.0731,  0.1339,\n",
       "           0.8232, -0.4580, -1.3033, -0.1165,  0.0802]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.3747, -0.3154,  1.9973],\n",
       "          [-0.8798,  0.6050,  0.5201],\n",
       "          [ 0.0861, -0.6723,  2.0650]],\n",
       "\n",
       "         [[ 1.5016,  0.1367,  0.7747],\n",
       "          [ 1.5696, -1.1369,  1.2308],\n",
       "          [-0.3342, -0.1066, -0.9368]],\n",
       "\n",
       "         [[-0.4879, -2.2326, -0.3182],\n",
       "          [-0.3219,  1.2360, -0.4541],\n",
       "          [ 0.0530,  1.0489,  0.7111]],\n",
       "\n",
       "         [[-1.1270, -1.4711, -0.3569],\n",
       "          [ 0.9117, -1.5560, -0.5282],\n",
       "          [-0.4072, -0.1465,  0.5948]]],\n",
       "\n",
       "\n",
       "        [[[-0.5127,  0.5897,  3.1053],\n",
       "          [ 0.3378,  0.5325, -0.1929],\n",
       "          [ 1.2226,  1.5711, -0.4486]],\n",
       "\n",
       "         [[ 0.6968,  0.6136, -0.1065],\n",
       "          [ 0.0176,  0.5653,  1.3824],\n",
       "          [ 0.2924,  0.1485, -0.8486]],\n",
       "\n",
       "         [[ 0.1887,  0.7772,  1.0469],\n",
       "          [ 1.2239,  1.4021,  0.2207],\n",
       "          [-0.1540, -1.4175,  0.2750]],\n",
       "\n",
       "         [[ 0.8286, -0.1791,  1.1441],\n",
       "          [ 0.1849, -0.9061,  0.4841],\n",
       "          [-0.7457,  0.3570, -0.7237]]],\n",
       "\n",
       "\n",
       "        [[[-0.7684, -0.5854, -1.2868],\n",
       "          [ 2.0958, -1.1765,  0.7071],\n",
       "          [-0.9462,  0.9571,  2.2896]],\n",
       "\n",
       "         [[-0.5021,  0.2955, -1.0912],\n",
       "          [ 2.3668,  0.2622, -0.1157],\n",
       "          [ 0.5583,  1.4044, -1.8133]],\n",
       "\n",
       "         [[ 0.0700,  1.5920,  0.0055],\n",
       "          [-1.6553, -0.3449,  0.3250],\n",
       "          [ 0.1952, -1.6929, -2.0366]],\n",
       "\n",
       "         [[ 0.3954, -0.1545,  0.1759],\n",
       "          [ 0.5074, -0.6900, -1.3982],\n",
       "          [ 0.7649,  0.9587, -1.3545]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4751, -0.6453, -1.4215],\n",
       "          [ 0.4864,  0.0309,  1.7248],\n",
       "          [ 0.6930, -1.6747, -0.0148]],\n",
       "\n",
       "         [[ 1.9821, -0.5885, -0.4824],\n",
       "          [-0.6815, -1.0453, -0.2519],\n",
       "          [ 0.7716, -0.7769, -0.0731]],\n",
       "\n",
       "         [[-0.0136, -0.3013,  0.0614],\n",
       "          [-0.9613, -0.3394, -0.2800],\n",
       "          [ 0.1339,  0.8232, -0.4580]],\n",
       "\n",
       "         [[-0.0319, -1.8799,  0.6918],\n",
       "          [-1.2815, -0.4324, -0.5585],\n",
       "          [-1.3033, -0.1165,  0.0802]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = original_tensor.view(original_tensor.shape[0], original_tensor.shape[1], 4, 3).transpose(1,2)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.3747, -0.3154,  1.9973],\n",
       "          [ 1.5016,  0.1367,  0.7747],\n",
       "          [-0.4879, -2.2326, -0.3182],\n",
       "          [-1.1270, -1.4711, -0.3569]],\n",
       "\n",
       "         [[-0.8798,  0.6050,  0.5201],\n",
       "          [ 1.5696, -1.1369,  1.2308],\n",
       "          [-0.3219,  1.2360, -0.4541],\n",
       "          [ 0.9117, -1.5560, -0.5282]],\n",
       "\n",
       "         [[ 0.0861, -0.6723,  2.0650],\n",
       "          [-0.3342, -0.1066, -0.9368],\n",
       "          [ 0.0530,  1.0489,  0.7111],\n",
       "          [-0.4072, -0.1465,  0.5948]]],\n",
       "\n",
       "\n",
       "        [[[-0.5127,  0.5897,  3.1053],\n",
       "          [ 0.6968,  0.6136, -0.1065],\n",
       "          [ 0.1887,  0.7772,  1.0469],\n",
       "          [ 0.8286, -0.1791,  1.1441]],\n",
       "\n",
       "         [[ 0.3378,  0.5325, -0.1929],\n",
       "          [ 0.0176,  0.5653,  1.3824],\n",
       "          [ 1.2239,  1.4021,  0.2207],\n",
       "          [ 0.1849, -0.9061,  0.4841]],\n",
       "\n",
       "         [[ 1.2226,  1.5711, -0.4486],\n",
       "          [ 0.2924,  0.1485, -0.8486],\n",
       "          [-0.1540, -1.4175,  0.2750],\n",
       "          [-0.7457,  0.3570, -0.7237]]],\n",
       "\n",
       "\n",
       "        [[[-0.7684, -0.5854, -1.2868],\n",
       "          [-0.5021,  0.2955, -1.0912],\n",
       "          [ 0.0700,  1.5920,  0.0055],\n",
       "          [ 0.3954, -0.1545,  0.1759]],\n",
       "\n",
       "         [[ 2.0958, -1.1765,  0.7071],\n",
       "          [ 2.3668,  0.2622, -0.1157],\n",
       "          [-1.6553, -0.3449,  0.3250],\n",
       "          [ 0.5074, -0.6900, -1.3982]],\n",
       "\n",
       "         [[-0.9462,  0.9571,  2.2896],\n",
       "          [ 0.5583,  1.4044, -1.8133],\n",
       "          [ 0.1952, -1.6929, -2.0366],\n",
       "          [ 0.7649,  0.9587, -1.3545]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4751, -0.6453, -1.4215],\n",
       "          [ 1.9821, -0.5885, -0.4824],\n",
       "          [-0.0136, -0.3013,  0.0614],\n",
       "          [-0.0319, -1.8799,  0.6918]],\n",
       "\n",
       "         [[ 0.4864,  0.0309,  1.7248],\n",
       "          [-0.6815, -1.0453, -0.2519],\n",
       "          [-0.9613, -0.3394, -0.2800],\n",
       "          [-1.2815, -0.4324, -0.5585]],\n",
       "\n",
       "         [[ 0.6930, -1.6747, -0.0148],\n",
       "          [ 0.7716, -0.7769, -0.0731],\n",
       "          [ 0.1339,  0.8232, -0.4580],\n",
       "          [-1.3033, -0.1165,  0.0802]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this sapes the tensor into (batch, num_heads, seq_len, d_k)\n",
    "# 4,4,3,3\n",
    "j = original_tensor.view(4, 3,4, 3)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 3, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = original_tensor.view(4, 3,4, 3).transpose(2,1)\n",
    "j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3747, -0.3154,  1.9973,  1.5016,  0.1367,  0.7747, -0.4879,\n",
       "          -2.2326, -0.3182, -1.1270, -1.4711, -0.3569],\n",
       "         [-0.8798,  0.6050,  0.5201,  1.5696, -1.1369,  1.2308, -0.3219,\n",
       "           1.2360, -0.4541,  0.9117, -1.5560, -0.5282],\n",
       "         [ 0.0861, -0.6723,  2.0650, -0.3342, -0.1066, -0.9368,  0.0530,\n",
       "           1.0489,  0.7111, -0.4072, -0.1465,  0.5948]],\n",
       "\n",
       "        [[-0.5127,  0.5897,  3.1053,  0.6968,  0.6136, -0.1065,  0.1887,\n",
       "           0.7772,  1.0469,  0.8286, -0.1791,  1.1441],\n",
       "         [ 0.3378,  0.5325, -0.1929,  0.0176,  0.5653,  1.3824,  1.2239,\n",
       "           1.4021,  0.2207,  0.1849, -0.9061,  0.4841],\n",
       "         [ 1.2226,  1.5711, -0.4486,  0.2924,  0.1485, -0.8486, -0.1540,\n",
       "          -1.4175,  0.2750, -0.7457,  0.3570, -0.7237]],\n",
       "\n",
       "        [[-0.7684, -0.5854, -1.2868, -0.5021,  0.2955, -1.0912,  0.0700,\n",
       "           1.5920,  0.0055,  0.3954, -0.1545,  0.1759],\n",
       "         [ 2.0958, -1.1765,  0.7071,  2.3668,  0.2622, -0.1157, -1.6553,\n",
       "          -0.3449,  0.3250,  0.5074, -0.6900, -1.3982],\n",
       "         [-0.9462,  0.9571,  2.2896,  0.5583,  1.4044, -1.8133,  0.1952,\n",
       "          -1.6929, -2.0366,  0.7649,  0.9587, -1.3545]],\n",
       "\n",
       "        [[ 0.4751, -0.6453, -1.4215,  1.9821, -0.5885, -0.4824, -0.0136,\n",
       "          -0.3013,  0.0614, -0.0319, -1.8799,  0.6918],\n",
       "         [ 0.4864,  0.0309,  1.7248, -0.6815, -1.0453, -0.2519, -0.9613,\n",
       "          -0.3394, -0.2800, -1.2815, -0.4324, -0.5585],\n",
       "         [ 0.6930, -1.6747, -0.0148,  0.7716, -0.7769, -0.0731,  0.1339,\n",
       "           0.8232, -0.4580, -1.3033, -0.1165,  0.0802]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = j.transpose(2,1)\n",
    "j.reshape(j.shape[0], j.shape[1], 3*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0987, -0.9672],\n",
       "        [-0.8051,  1.3027],\n",
       "        [-0.7114,  0.5448]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aj = torch.randn(3,2)\n",
    "aj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0657],\n",
       "        [ 0.2488],\n",
       "        [-0.0833]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jk =torch.mean(aj, dim=1)\n",
    "jk.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[1, 2, 3],\n",
    "                             [4, 0, 0],\n",
    "                             [5, 6, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[1, 2, 0],\n",
      "        [4, 0, 0],\n",
      "        [5, 6, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Define the padding value\n",
    "padding_value = 3\n",
    "\n",
    "# Create the padding mask\n",
    "padding_mask = (input_tensor != padding_value).int()\n",
    "print(padding_mask)\n",
    "\n",
    "masked_tensor = input_tensor * padding_mask\n",
    "\n",
    "print(masked_tensor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.zeros(5,6)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(3,4, 5,6)\n",
    "t.shape\n",
    "f = t * j\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.Embedding(10,2, padding_idx=5)\n",
    "l(torch.tensor([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.ones(3,5)\n",
    "f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.ones(4, 3,5)\n",
    "j\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f + j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

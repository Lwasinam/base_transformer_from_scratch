{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "def add(num):\n",
    "    return num +1\n",
    "\n",
    "\n",
    "x = 3\n",
    "for i in range(10):\n",
    "    x = add(x)\n",
    "print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3702, -0.9734, -2.0180, -1.7274],\n",
       "         [-1.0941, -0.3457, -0.4963, -1.3405],\n",
       "         [ 0.9665, -0.1556, -0.1646, -1.1247],\n",
       "         [ 0.5573, -1.1089, -1.4305, -0.1664],\n",
       "         [-1.3292, -0.1934,  1.1951,  0.4222]],\n",
       "\n",
       "        [[ 1.0810,  1.2269,  0.8059,  0.0886],\n",
       "         [ 0.4564,  0.8382, -0.8297,  0.2976],\n",
       "         [ 0.6037,  0.5643,  0.8450,  0.3196],\n",
       "         [ 0.0700, -0.8949,  0.9775,  0.6022],\n",
       "         [ 2.3541,  0.3687,  0.9792,  0.4612]],\n",
       "\n",
       "        [[ 0.6204, -0.4519,  0.2207, -0.2403],\n",
       "         [-1.4087,  1.3106,  1.7071,  0.1296],\n",
       "         [-0.9428, -1.3478,  0.8620, -0.8970],\n",
       "         [-1.9424,  1.9631, -1.5458,  0.9840],\n",
       "         [ 0.9040, -0.1328, -0.3945, -1.4670]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.randn(3,5,4)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8511, 0.0817, 0.0287, 0.0384],\n",
       "         [0.1750, 0.3699, 0.3182, 0.1368],\n",
       "         [0.5644, 0.1838, 0.1821, 0.0697],\n",
       "         [0.5522, 0.1043, 0.0757, 0.2678],\n",
       "         [0.0447, 0.1393, 0.5583, 0.2577]],\n",
       "\n",
       "        [[0.3042, 0.3520, 0.2310, 0.1128],\n",
       "         [0.2782, 0.4076, 0.0769, 0.2374],\n",
       "         [0.2508, 0.2411, 0.3193, 0.1888],\n",
       "         [0.1798, 0.0685, 0.4456, 0.3061],\n",
       "         [0.6490, 0.0891, 0.1641, 0.0978]],\n",
       "\n",
       "        [[0.4106, 0.1405, 0.2753, 0.1736],\n",
       "         [0.0231, 0.3497, 0.5199, 0.1074],\n",
       "         [0.1137, 0.0759, 0.6914, 0.1191],\n",
       "         [0.0141, 0.7014, 0.0210, 0.2635],\n",
       "         [0.5811, 0.2060, 0.1586, 0.0543]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.softmax( dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1186,  0.0817, -0.7493, -0.1087],\n",
       "        [ 0.6830, -0.5266, -1.2983,  0.2962],\n",
       "        [-1.5785,  0.7623,  0.0662, -0.4074],\n",
       "        [-0.1217,  0.0666, -0.3907,  0.0965],\n",
       "        [-1.6425,  0.0318, -1.2116,  1.5726],\n",
       "        [-0.0526, -0.1219, -0.4346,  0.4086],\n",
       "        [ 0.0985,  0.5565, -0.7304,  0.1291],\n",
       "        [ 0.5877, -1.4460,  0.3380,  1.2966],\n",
       "        [ 0.0391,  1.9948,  0.5572, -0.0736],\n",
       "        [ 1.0560,  2.0222,  1.4077,  0.0784],\n",
       "        [-0.9867,  0.3948, -2.8570,  0.2800],\n",
       "        [ 0.0875,  1.5100,  1.6393, -1.0153],\n",
       "        [-0.2597, -0.1747,  0.7246, -0.2850],\n",
       "        [ 0.3620, -0.3157,  0.3002,  1.1716],\n",
       "        [ 0.6559,  0.9599, -0.2290,  1.1106]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.view(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8638, -0.8031, -1.7960, -0.0873,  0.2826],\n",
       "        [ 1.4938,  1.7694,  0.3406,  0.6390, -0.3245],\n",
       "        [ 1.0373,  0.5098,  2.0853,  1.9720, -0.3262]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab = torch.randn(3,5)\n",
    "lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8638, -0.8031, -1.7960, -0.0873,  0.2826,  1.4938,  1.7694,  0.3406,\n",
       "         0.6390, -0.3245,  1.0373,  0.5098,  2.0853,  1.9720, -0.3262])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.view(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from datasets import load_dataset\n",
    "\n",
    "def get_story_in_lang(lang):\n",
    "    ds_raw = load_dataset('opus_books', 'en-it', split = 'train')\n",
    "    for item in ds_raw:\n",
    "        yield item['translation'][lang]\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[SOS]\", \"[EOS]\", \"[PAD]\"])\n",
    "\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "tokenizer.train_from_iterator(get_story_in_lang('en'), trainer = trainer)\n",
    "tokenizer.save(\"tokenizer-wiki.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.5119e-02, 6.3096e-04, 1.5849e-05, 3.9811e-07])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.pow(10,  torch.arange(0,5)*-4/512)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9647, 0.9647, 0.9647, 0.9647],\n",
       "         [0.9306, 0.9306, 0.9306, 0.9306],\n",
       "         [0.8977, 0.8977, 0.8977, 0.8977],\n",
       "         [0.8660, 0.8660, 0.8660, 0.8660],\n",
       "         [0.8354, 0.8354, 0.8354, 0.8354]],\n",
       "\n",
       "        [[0.9647, 0.9647, 0.9647, 0.9647],\n",
       "         [0.9306, 0.9306, 0.9306, 0.9306],\n",
       "         [0.8977, 0.8977, 0.8977, 0.8977],\n",
       "         [0.8660, 0.8660, 0.8660, 0.8660],\n",
       "         [0.8354, 0.8354, 0.8354, 0.8354]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.ones(2, 5,4)\n",
    "\n",
    "\n",
    "pe[: ,:] / (10000**((2*torch.arange(1, 6).unsqueeze(1)/512)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.5119e-02, 6.3096e-04])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_term = torch.exp(torch.arange(0, 5, 2) * -(np.log(10000.0) / 5))\n",
    "div_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 5, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l  = torch.arange(5).unsqueeze(1)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.1544e-03, 4.6416e-06])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_term = torch.exp(torch.arange(0, 6, 2) * -(math.log(10000.0) / 3))\n",
    "div_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.ones(5,6)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe[:,0::2] = torch.sin(l/div_term)\n",
    "pe[:, 1::2] = torch.cos(l/div_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403, -0.7151,  0.6990, -0.6469,  0.7626],\n",
       "        [ 0.9093, -0.4161, -0.9997, -0.0229, -0.9866,  0.1631],\n",
       "        [ 0.1411, -0.9900, -0.6824, -0.7310, -0.8579, -0.5139],\n",
       "        [-0.7568, -0.6536,  0.0457, -0.9990, -0.3218, -0.9468]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.,  9., 16.])\n"
     ]
    }
   ],
   "source": [
    "pe = pe[:,0::2] * div_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =  torch.ones(3, 5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(1, 5)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(tensor([[0, 1],\n",
      "        [4, 5],\n",
      "        [8, 9]]), tensor([[ 2,  3],\n",
      "        [ 6,  7],\n",
      "        [10, 11]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "tensor = torch.arange(12).reshape(3, 4)  # Example tensor of shape (3, 4)\n",
    "\n",
    "# Define the number of parts (n)\n",
    "n = 2\n",
    "\n",
    "\n",
    "print(tensor.size(1))\n",
    "# Calculate the number of columns per part\n",
    "columns_per_part = tensor.size(1) // n\n",
    "\n",
    "# Split the tensor into n parts horizontally\n",
    "parts = torch.split(tensor, columns_per_part, dim=1)\n",
    "\n",
    "print(parts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7,8,9]])\n",
    "original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 6]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reshaped_tensor \u001b[39m=\u001b[39m original_tensor\u001b[39m.\u001b[39;49mview(\u001b[39m1\u001b[39;49m, \u001b[39m6\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m reshaped_tensor\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 6]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "reshaped_tensor = original_tensor.view(1, 6)\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a tensor with 8 columns\n",
    "original_tensor = torch.randn((4,3,12))  # 10 rows, 8 columns\n",
    "\n",
    "# Reshape into two tensors with 4 columns each\n",
    "# tensor1 = original_tensor.view(10, 4)\n",
    "# tensor2 = original_tensor.view(10, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3747, -0.3154,  1.9973,  1.5016,  0.1367,  0.7747, -0.4879,\n",
       "          -2.2326, -0.3182, -1.1270, -1.4711, -0.3569],\n",
       "         [-0.8798,  0.6050,  0.5201,  1.5696, -1.1369,  1.2308, -0.3219,\n",
       "           1.2360, -0.4541,  0.9117, -1.5560, -0.5282],\n",
       "         [ 0.0861, -0.6723,  2.0650, -0.3342, -0.1066, -0.9368,  0.0530,\n",
       "           1.0489,  0.7111, -0.4072, -0.1465,  0.5948]],\n",
       "\n",
       "        [[-0.5127,  0.5897,  3.1053,  0.6968,  0.6136, -0.1065,  0.1887,\n",
       "           0.7772,  1.0469,  0.8286, -0.1791,  1.1441],\n",
       "         [ 0.3378,  0.5325, -0.1929,  0.0176,  0.5653,  1.3824,  1.2239,\n",
       "           1.4021,  0.2207,  0.1849, -0.9061,  0.4841],\n",
       "         [ 1.2226,  1.5711, -0.4486,  0.2924,  0.1485, -0.8486, -0.1540,\n",
       "          -1.4175,  0.2750, -0.7457,  0.3570, -0.7237]],\n",
       "\n",
       "        [[-0.7684, -0.5854, -1.2868, -0.5021,  0.2955, -1.0912,  0.0700,\n",
       "           1.5920,  0.0055,  0.3954, -0.1545,  0.1759],\n",
       "         [ 2.0958, -1.1765,  0.7071,  2.3668,  0.2622, -0.1157, -1.6553,\n",
       "          -0.3449,  0.3250,  0.5074, -0.6900, -1.3982],\n",
       "         [-0.9462,  0.9571,  2.2896,  0.5583,  1.4044, -1.8133,  0.1952,\n",
       "          -1.6929, -2.0366,  0.7649,  0.9587, -1.3545]],\n",
       "\n",
       "        [[ 0.4751, -0.6453, -1.4215,  1.9821, -0.5885, -0.4824, -0.0136,\n",
       "          -0.3013,  0.0614, -0.0319, -1.8799,  0.6918],\n",
       "         [ 0.4864,  0.0309,  1.7248, -0.6815, -1.0453, -0.2519, -0.9613,\n",
       "          -0.3394, -0.2800, -1.2815, -0.4324, -0.5585],\n",
       "         [ 0.6930, -1.6747, -0.0148,  0.7716, -0.7769, -0.0731,  0.1339,\n",
       "           0.8232, -0.4580, -1.3033, -0.1165,  0.0802]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.3747, -0.3154,  1.9973],\n",
       "          [-0.8798,  0.6050,  0.5201],\n",
       "          [ 0.0861, -0.6723,  2.0650]],\n",
       "\n",
       "         [[ 1.5016,  0.1367,  0.7747],\n",
       "          [ 1.5696, -1.1369,  1.2308],\n",
       "          [-0.3342, -0.1066, -0.9368]],\n",
       "\n",
       "         [[-0.4879, -2.2326, -0.3182],\n",
       "          [-0.3219,  1.2360, -0.4541],\n",
       "          [ 0.0530,  1.0489,  0.7111]],\n",
       "\n",
       "         [[-1.1270, -1.4711, -0.3569],\n",
       "          [ 0.9117, -1.5560, -0.5282],\n",
       "          [-0.4072, -0.1465,  0.5948]]],\n",
       "\n",
       "\n",
       "        [[[-0.5127,  0.5897,  3.1053],\n",
       "          [ 0.3378,  0.5325, -0.1929],\n",
       "          [ 1.2226,  1.5711, -0.4486]],\n",
       "\n",
       "         [[ 0.6968,  0.6136, -0.1065],\n",
       "          [ 0.0176,  0.5653,  1.3824],\n",
       "          [ 0.2924,  0.1485, -0.8486]],\n",
       "\n",
       "         [[ 0.1887,  0.7772,  1.0469],\n",
       "          [ 1.2239,  1.4021,  0.2207],\n",
       "          [-0.1540, -1.4175,  0.2750]],\n",
       "\n",
       "         [[ 0.8286, -0.1791,  1.1441],\n",
       "          [ 0.1849, -0.9061,  0.4841],\n",
       "          [-0.7457,  0.3570, -0.7237]]],\n",
       "\n",
       "\n",
       "        [[[-0.7684, -0.5854, -1.2868],\n",
       "          [ 2.0958, -1.1765,  0.7071],\n",
       "          [-0.9462,  0.9571,  2.2896]],\n",
       "\n",
       "         [[-0.5021,  0.2955, -1.0912],\n",
       "          [ 2.3668,  0.2622, -0.1157],\n",
       "          [ 0.5583,  1.4044, -1.8133]],\n",
       "\n",
       "         [[ 0.0700,  1.5920,  0.0055],\n",
       "          [-1.6553, -0.3449,  0.3250],\n",
       "          [ 0.1952, -1.6929, -2.0366]],\n",
       "\n",
       "         [[ 0.3954, -0.1545,  0.1759],\n",
       "          [ 0.5074, -0.6900, -1.3982],\n",
       "          [ 0.7649,  0.9587, -1.3545]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4751, -0.6453, -1.4215],\n",
       "          [ 0.4864,  0.0309,  1.7248],\n",
       "          [ 0.6930, -1.6747, -0.0148]],\n",
       "\n",
       "         [[ 1.9821, -0.5885, -0.4824],\n",
       "          [-0.6815, -1.0453, -0.2519],\n",
       "          [ 0.7716, -0.7769, -0.0731]],\n",
       "\n",
       "         [[-0.0136, -0.3013,  0.0614],\n",
       "          [-0.9613, -0.3394, -0.2800],\n",
       "          [ 0.1339,  0.8232, -0.4580]],\n",
       "\n",
       "         [[-0.0319, -1.8799,  0.6918],\n",
       "          [-1.2815, -0.4324, -0.5585],\n",
       "          [-1.3033, -0.1165,  0.0802]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = original_tensor.view(original_tensor.shape[0], original_tensor.shape[1], 4, 3).transpose(1,2)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.3747, -0.3154,  1.9973],\n",
       "          [ 1.5016,  0.1367,  0.7747],\n",
       "          [-0.4879, -2.2326, -0.3182],\n",
       "          [-1.1270, -1.4711, -0.3569]],\n",
       "\n",
       "         [[-0.8798,  0.6050,  0.5201],\n",
       "          [ 1.5696, -1.1369,  1.2308],\n",
       "          [-0.3219,  1.2360, -0.4541],\n",
       "          [ 0.9117, -1.5560, -0.5282]],\n",
       "\n",
       "         [[ 0.0861, -0.6723,  2.0650],\n",
       "          [-0.3342, -0.1066, -0.9368],\n",
       "          [ 0.0530,  1.0489,  0.7111],\n",
       "          [-0.4072, -0.1465,  0.5948]]],\n",
       "\n",
       "\n",
       "        [[[-0.5127,  0.5897,  3.1053],\n",
       "          [ 0.6968,  0.6136, -0.1065],\n",
       "          [ 0.1887,  0.7772,  1.0469],\n",
       "          [ 0.8286, -0.1791,  1.1441]],\n",
       "\n",
       "         [[ 0.3378,  0.5325, -0.1929],\n",
       "          [ 0.0176,  0.5653,  1.3824],\n",
       "          [ 1.2239,  1.4021,  0.2207],\n",
       "          [ 0.1849, -0.9061,  0.4841]],\n",
       "\n",
       "         [[ 1.2226,  1.5711, -0.4486],\n",
       "          [ 0.2924,  0.1485, -0.8486],\n",
       "          [-0.1540, -1.4175,  0.2750],\n",
       "          [-0.7457,  0.3570, -0.7237]]],\n",
       "\n",
       "\n",
       "        [[[-0.7684, -0.5854, -1.2868],\n",
       "          [-0.5021,  0.2955, -1.0912],\n",
       "          [ 0.0700,  1.5920,  0.0055],\n",
       "          [ 0.3954, -0.1545,  0.1759]],\n",
       "\n",
       "         [[ 2.0958, -1.1765,  0.7071],\n",
       "          [ 2.3668,  0.2622, -0.1157],\n",
       "          [-1.6553, -0.3449,  0.3250],\n",
       "          [ 0.5074, -0.6900, -1.3982]],\n",
       "\n",
       "         [[-0.9462,  0.9571,  2.2896],\n",
       "          [ 0.5583,  1.4044, -1.8133],\n",
       "          [ 0.1952, -1.6929, -2.0366],\n",
       "          [ 0.7649,  0.9587, -1.3545]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4751, -0.6453, -1.4215],\n",
       "          [ 1.9821, -0.5885, -0.4824],\n",
       "          [-0.0136, -0.3013,  0.0614],\n",
       "          [-0.0319, -1.8799,  0.6918]],\n",
       "\n",
       "         [[ 0.4864,  0.0309,  1.7248],\n",
       "          [-0.6815, -1.0453, -0.2519],\n",
       "          [-0.9613, -0.3394, -0.2800],\n",
       "          [-1.2815, -0.4324, -0.5585]],\n",
       "\n",
       "         [[ 0.6930, -1.6747, -0.0148],\n",
       "          [ 0.7716, -0.7769, -0.0731],\n",
       "          [ 0.1339,  0.8232, -0.4580],\n",
       "          [-1.3033, -0.1165,  0.0802]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this sapes the tensor into (batch, num_heads, seq_len, d_k)\n",
    "# 4,4,3,3\n",
    "j = original_tensor.view(4, 3,4, 3)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 3, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = original_tensor.view(4, 3,4, 3).transpose(2,1)\n",
    "j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3747, -0.3154,  1.9973,  1.5016,  0.1367,  0.7747, -0.4879,\n",
       "          -2.2326, -0.3182, -1.1270, -1.4711, -0.3569],\n",
       "         [-0.8798,  0.6050,  0.5201,  1.5696, -1.1369,  1.2308, -0.3219,\n",
       "           1.2360, -0.4541,  0.9117, -1.5560, -0.5282],\n",
       "         [ 0.0861, -0.6723,  2.0650, -0.3342, -0.1066, -0.9368,  0.0530,\n",
       "           1.0489,  0.7111, -0.4072, -0.1465,  0.5948]],\n",
       "\n",
       "        [[-0.5127,  0.5897,  3.1053,  0.6968,  0.6136, -0.1065,  0.1887,\n",
       "           0.7772,  1.0469,  0.8286, -0.1791,  1.1441],\n",
       "         [ 0.3378,  0.5325, -0.1929,  0.0176,  0.5653,  1.3824,  1.2239,\n",
       "           1.4021,  0.2207,  0.1849, -0.9061,  0.4841],\n",
       "         [ 1.2226,  1.5711, -0.4486,  0.2924,  0.1485, -0.8486, -0.1540,\n",
       "          -1.4175,  0.2750, -0.7457,  0.3570, -0.7237]],\n",
       "\n",
       "        [[-0.7684, -0.5854, -1.2868, -0.5021,  0.2955, -1.0912,  0.0700,\n",
       "           1.5920,  0.0055,  0.3954, -0.1545,  0.1759],\n",
       "         [ 2.0958, -1.1765,  0.7071,  2.3668,  0.2622, -0.1157, -1.6553,\n",
       "          -0.3449,  0.3250,  0.5074, -0.6900, -1.3982],\n",
       "         [-0.9462,  0.9571,  2.2896,  0.5583,  1.4044, -1.8133,  0.1952,\n",
       "          -1.6929, -2.0366,  0.7649,  0.9587, -1.3545]],\n",
       "\n",
       "        [[ 0.4751, -0.6453, -1.4215,  1.9821, -0.5885, -0.4824, -0.0136,\n",
       "          -0.3013,  0.0614, -0.0319, -1.8799,  0.6918],\n",
       "         [ 0.4864,  0.0309,  1.7248, -0.6815, -1.0453, -0.2519, -0.9613,\n",
       "          -0.3394, -0.2800, -1.2815, -0.4324, -0.5585],\n",
       "         [ 0.6930, -1.6747, -0.0148,  0.7716, -0.7769, -0.0731,  0.1339,\n",
       "           0.8232, -0.4580, -1.3033, -0.1165,  0.0802]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = j.transpose(2,1)\n",
    "j.reshape(j.shape[0], j.shape[1], 3*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0987, -0.9672],\n",
       "        [-0.8051,  1.3027],\n",
       "        [-0.7114,  0.5448]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aj = torch.randn(3,2)\n",
    "aj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0657],\n",
       "        [ 0.2488],\n",
       "        [-0.0833]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jk =torch.mean(aj, dim=1)\n",
    "jk.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[1, 2, 3],\n",
    "                             [4, 0, 0],\n",
    "                             [5, 6, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[1, 2, 0],\n",
      "        [4, 0, 0],\n",
      "        [5, 6, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Define the padding value\n",
    "padding_value = 3\n",
    "\n",
    "# Create the padding mask\n",
    "padding_mask = (input_tensor != padding_value).int()\n",
    "print(padding_mask)\n",
    "\n",
    "masked_tensor = input_tensor * padding_mask\n",
    "\n",
    "print(masked_tensor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.zeros(5,6)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(3,4, 5,6)\n",
    "t.shape\n",
    "f = t * j\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.Embedding(10,2, padding_idx=5)\n",
    "l(torch.tensor([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.ones(3,5)\n",
    "f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.ones(4, 3,5)\n",
    "j\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f + j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.zeros(5,3)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5930, -0.3619, -1.9371]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.randn(1,3)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5930])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, next_WORD = torch.max(p, dim=1)\n",
    "_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = p.masked_fill(mask == 0, 3)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A():\n",
    "    def __init__(self, num, num2):\n",
    "        self.a = num\n",
    "        self.b = num2\n",
    "    def sum(self):\n",
    "        return self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A.__init__() missing 2 required positional arguments: 'num' and 'num2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lwasinam/AI_Projects/base_transformer/test.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lwasinam/AI_Projects/base_transformer/test.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m A()\u001b[39m.\u001b[39msum()\n",
      "\u001b[0;31mTypeError\u001b[0m: A.__init__() missing 2 required positional arguments: 'num' and 'num2'"
     ]
    }
   ],
   "source": [
    "A().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
